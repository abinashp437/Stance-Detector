{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_fnc.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPVR0ynOzWrbMbexvEXe9Ey",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abinashp437/Stance_Detection_FNC_1/blob/main/lstm_fnc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UmDW7oZ1i9_",
        "outputId": "bec80309-b626-48fd-f599-96af0c4a29f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords') #for stopword removal\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from google.colab import files\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQlrw8Js5tEp"
      },
      "source": [
        "body_url = \"https://raw.githubusercontent.com/abinashp437/Stance_Detection_FNC_1/main/fnc_1_data/train_bodies.csv\"\n",
        "body = pd.read_csv(body_url)\n",
        "stance_url = \"https://raw.githubusercontent.com/abinashp437/Stance_Detection_FNC_1/main/fnc_1_data/train_stances.csv\"\n",
        "stance = pd.read_csv(stance_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfQzuacW6BLY",
        "outputId": "946ff415-01d9-4a00-ff2c-7702528e0f5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for row_id, art in body.iterrows():\n",
        "  body['articleBody'][row_id] = art['articleBody'].replace('\\n','')\n",
        "for row_id, stan in stance.iterrows():\n",
        "  stance['Headline'][row_id] = stan['Headline'].replace('\\n','')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMqtBPG16b79",
        "outputId": "846827dd-b6d5-4e66-d150-9dfec783499e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "stop_words = stopwords.words('english')\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "for row_id, art in body.iterrows():\n",
        "  body['articleBody'][row_id] = ' '.join([word for word in art['articleBody'].split() if word not in stop_words])\n",
        "for row_id, head in stance.iterrows():\n",
        "  stance['Headline'][row_id] = ' '.join([word for word in head['Headline'].split() if word not in stop_words])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DarDlVmL6foa",
        "outputId": "11f8df32-af3b-4f9d-8043-b0a40d7f0e9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "def lemmatize(text):\n",
        "  return [lemmatizer.lemmatize(word) for word in w_tokenizer.tokenize(text)]\n",
        "\n",
        "for row_id, art in body.iterrows():\n",
        "  body['articleBody'][row_id] = ' '.join(lemmatize(art['articleBody']))\n",
        "\n",
        "for row_id, head in stance.iterrows():\n",
        "  stance['Headline'][row_id] = ' '.join(lemmatize(head['Headline']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2PORhTf6pus",
        "outputId": "f0e2567c-a357-4010-976f-478e3a95a67a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for row_id, art in body.iterrows():\n",
        "  body['articleBody'][row_id] = art['articleBody'].lower()\n",
        "\n",
        "for row_id, head in stance.iterrows():\n",
        "  stance['Headline'][row_id] = head['Headline'].lower()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GYcGSP46vnZ"
      },
      "source": [
        "corpus = []\n",
        "for row_id, art in body.iterrows():\n",
        "  corpus.append(w_tokenizer.tokenize(art['articleBody']))\n",
        "\n",
        "for row_id, head in stance.iterrows():\n",
        "  corpus.append(w_tokenizer.tokenize(head['Headline']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8p6L5aN6-zG",
        "outputId": "476494a8-e613-4a81-fb9b-7e4519de525b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pad_art = 180\n",
        "pad_head = 11\n",
        "for row_id, art in body.iterrows():\n",
        "  body['articleBody'][row_id] = ' '.join(w_tokenizer.tokenize(art['articleBody'])[:pad_art])\n",
        "\n",
        "for row_id, head in stance.iterrows():\n",
        "  stance['Headline'][row_id] = ' '.join(w_tokenizer.tokenize(head['Headline'])[:pad_head])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_4E8tqM7DPj",
        "outputId": "3e69aabf-ef4e-41b6-b05c-ee7f25830e94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Word2Vec(corpus, min_count = 1, size = 100, workers = 3, window = 3, iter = 30)\n",
        "def vectorize(text):\n",
        "  return [model[word] for word in w_tokenizer.tokenize(text)]\n",
        "\n",
        "art_vec = pd.Series([], dtype = float)\n",
        "for row_id, art in body.iterrows():\n",
        "  art_vec[row_id] = vectorize(art['articleBody'])\n",
        "\n",
        "head_vec = pd.Series([], dtype = float)\n",
        "for row_id, head in stance.iterrows():\n",
        "  head_vec[row_id] = vectorize(head['Headline'])\n",
        "\n",
        "pad_art_vec = keras.preprocessing.sequence.pad_sequences(art_vec, padding = 'post', maxlen = pad_art, dtype = float)\n",
        "pad_head_vec = keras.preprocessing.sequence.pad_sequences(head_vec, padding = 'post', maxlen = pad_head, dtype = float)\n",
        "pad_art_vec = pad_art_vec.tolist()\n",
        "pad_head_vec = pad_head_vec.tolist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr05QQbV7fva"
      },
      "source": [
        "article_vector = pd.DataFrame()\n",
        "article_vector.insert(0, 'Body ID', body['Body ID'])\n",
        "article_vector.insert(1, 'Vectors', pad_art_vec)\n",
        "\n",
        "headline_vector = pd.DataFrame()\n",
        "headline_vector.insert(0, 'Body ID', stance['Body ID'])\n",
        "headline_vector.insert(1, 'Vectors', pad_head_vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS0jA2Hg_GI-"
      },
      "source": [
        "**Training and Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52BpkYdR8sm-"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, LSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q8MinBw_fh0"
      },
      "source": [
        "Stan_Id = pd.Series([], dtype = int)\n",
        "for row_id, stan in stance.iterrows():\n",
        "  if stan['Stance'] == 'unrelated':\n",
        "    Stan_Id[row_id] = 0\n",
        "  elif stan['Stance'] == 'agree':\n",
        "    Stan_Id[row_id] = 1\n",
        "  elif stan['Stance'] == 'disagree':\n",
        "    Stan_Id[row_id] = 2\n",
        "  elif stan['Stance'] == 'discuss':\n",
        "    Stan_Id[row_id] = 3\n",
        "\n",
        "headline_vector.insert(2, 'Stance ID', Stan_Id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zlxke9WQOmw"
      },
      "source": [
        "def train(headline, article):\n",
        "  x = []\n",
        "  y = []\n",
        "  for row_id, head in headline:\n",
        "    x.append([head['Vectors'], article['Body ID' == head['Body ID']]['Vectors']])\n",
        "    y.append(head['Stance ID'])\n",
        "  return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0j4SZpxPrVW",
        "outputId": "32cdd08d-8b6d-4359-80ce-f0bf5b800fca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train, y_train = train(headline_vector, article_vector)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-54e89073f522>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheadline_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticle_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-c9142fb5d44d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(headline, article)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mrow_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheadline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Vectors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Body ID'\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Body ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Vectors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Stance ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dpTkOLFM9Dv"
      },
      "source": [
        "def train_lstm(x_train, y_train, n):\n",
        "    model_lstm = keras.Sequential()\n",
        "\n",
        "    model_lstm.add(LSTM(50))\n",
        "    model_lstm.add(Dense(24,activation='sigmoid'))\n",
        "    model_lstm.add(Dense(6,activation='softmax'))\n",
        "\n",
        "    model_lstm.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    fitmodel = model_lstm.fit(x_train, y_train, epochs = 15,  verbose = 1, shuffle=False)   \n",
        "\n",
        "    # results = model_lstm.evaluate(x_test, y_test)\n",
        "    return results[1]*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duHa7BEZSOs_"
      },
      "source": [
        "x_train_dl = tf.convert_to_tensor(x_train, np.float32)\n",
        "y_train_dl = tf.convert_to_tensor(y_train, np.float32)\n",
        "\n",
        "for n in [round(_ * 0.1, 1) for _ in range(2, 9)]:\n",
        "  train_lstm(x_train_dl, y_train_dl, n)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}